{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10797536,"sourceType":"datasetVersion","datasetId":6701413},{"sourceId":10807452,"sourceType":"datasetVersion","datasetId":6708542}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Assignment: Image recognition\n- Alumno 1:\n- Alumno 2:\n- Alumno 3:\n\nThe goals of the assignment are:\n* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n\nFollow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/4oNHlRFEd71HXp4](https://drive.upm.es/s/4oNHlRFEd71HXp4)","metadata":{"editable":true,"id":"QYuALZOG-AMq","slideshow":{"slide_type":""},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.031186Z","start_time":"2024-10-26T00:00:17.131476Z"},"editable":true,"slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:03.824037Z","iopub.execute_input":"2025-02-24T14:00:03.824353Z","iopub.status.idle":"2025-02-24T14:00:16.711422Z","shell.execute_reply.started":"2025-02-24T14:00:03.824321Z","shell.execute_reply":"2025-02-24T14:00:16.710540Z"}},"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import uuid\nimport numpy as np\n\nclass GenericObject:\n    \"\"\"\n    Generic object data.\n    \"\"\"\n    def __init__(self):\n        self.id = uuid.uuid4()\n        self.bb = (-1, -1, -1, -1)\n        self.category= -1\n        self.score = -1\n\nclass GenericImage:\n    \"\"\"\n    Generic image data.\n    \"\"\"\n    def __init__(self, filename):\n        self.filename = filename\n        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n        self.objects = list([])\n\n    def add_object(self, obj: GenericObject):\n        self.objects.append(obj)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.066937Z","start_time":"2024-10-26T00:00:21.059126Z"},"editable":true,"id":"OYtqD3Oh-AMw","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:16.712386Z","iopub.execute_input":"2025-02-24T14:00:16.712863Z","iopub.status.idle":"2025-02-24T14:00:16.718241Z","shell.execute_reply.started":"2025-02-24T14:00:16.712838Z","shell.execute_reply":"2025-02-24T14:00:16.717420Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"categories = {0: 'Cargo plane', 1: 'Helicopter', 2: 'Small car', 3: 'Bus', 4: 'Truck', 5: 'Motorboat', 6: 'Fishing vessel', 7: 'Dump truck', 8: 'Excavator', 9: 'Building', 10: 'Storage tank', 11: 'Shipping container'}","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.153693Z","start_time":"2024-10-26T00:00:21.149079Z"},"id":"I_GygShu-AMz","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:16.719126Z","iopub.execute_input":"2025-02-24T14:00:16.719443Z","iopub.status.idle":"2025-02-24T14:00:16.867646Z","shell.execute_reply.started":"2025-02-24T14:00:16.719414Z","shell.execute_reply":"2025-02-24T14:00:16.866864Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install rasterio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:16.869191Z","iopub.execute_input":"2025-02-24T14:00:16.869422Z","iopub.status.idle":"2025-02-24T14:00:22.325495Z","shell.execute_reply.started":"2025-02-24T14:00:16.869402Z","shell.execute_reply":"2025-02-24T14:00:22.324503Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (25.1.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2025.1.31)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import warnings\nimport rasterio\nimport numpy as np\n\ndef load_geoimage(filename):\n    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n    src_raster = rasterio.open('/kaggle/input/deep-learning/xview_recognition/'+filename, 'r')\n    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n    input_type = src_raster.profile['dtype']\n    input_channels = src_raster.count\n    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n    for band in range(input_channels):\n        img[:, :, band] = src_raster.read(band+1)\n    return img","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.292654Z","start_time":"2024-10-26T00:00:21.205321Z"},"editable":true,"id":"fRBA7ReQ-AM0","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:22.326980Z","iopub.execute_input":"2025-02-24T14:00:22.327288Z","iopub.status.idle":"2025-02-24T14:00:22.898213Z","shell.execute_reply.started":"2025-02-24T14:00:22.327266Z","shell.execute_reply":"2025-02-24T14:00:22.897556Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"#### Training\nDesign and train a ffNN to deal with the “xview_recognition” classification task.","metadata":{"id":"diNBB3qy-AM2"}},{"cell_type":"code","source":"import json\n# Load database\n\njson_file = '/kaggle/input/deep-learning/xview_recognition/xview_ann_train.json' \nwith open(json_file) as ifs:\n    json_data = json.load(ifs)\nifs.close()","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.416449Z","start_time":"2024-10-26T00:00:21.311510Z"},"editable":true,"id":"Orto292C-AM3","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:22.898896Z","iopub.execute_input":"2025-02-24T14:00:22.899340Z","iopub.status.idle":"2025-02-24T14:00:23.072485Z","shell.execute_reply.started":"2025-02-24T14:00:22.899317Z","shell.execute_reply":"2025-02-24T14:00:23.071621Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\ncounts = dict.fromkeys(categories.values(), 0)\nanns = []\nfor json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n    image = GenericImage(json_img['filename'])\n    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n    obj = GenericObject()\n    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n    obj.category = json_ann['category_id']\n    # Resampling strategy to reduce training time\n    counts[obj.category] += 1\n    image.add_object(obj)\n    anns.append(image)\nprint(counts)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:22.874518Z","start_time":"2024-10-26T00:00:22.204948Z"},"id":"4GjFLHs4-AM4","outputId":"5581df22-d4e9-42ac-9f94-061fd8c7acd9","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:23.073481Z","iopub.execute_input":"2025-02-24T14:00:23.073793Z","iopub.status.idle":"2025-02-24T14:00:23.475241Z","shell.execute_reply.started":"2025-02-24T14:00:23.073765Z","shell.execute_reply":"2025-02-24T14:00:23.474540Z"}},"outputs":[{"name":"stdout","text":"{'Cargo plane': 635, 'Helicopter': 70, 'Small car': 4290, 'Bus': 2155, 'Truck': 2746, 'Motorboat': 1069, 'Fishing vessel': 706, 'Dump truck': 1236, 'Excavator': 789, 'Building': 4689, 'Storage tank': 1469, 'Shipping container': 1523}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nlabels = [image.objects[0].category for image in anns]\nanns_train, anns_valid = train_test_split(anns, test_size=0.12, random_state=1, shuffle=True, stratify=labels)\nprint('Number of training images: ' + str(len(anns_train)))\nprint('Number of validation images: ' + str(len(anns_valid)))","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:23.656800Z","start_time":"2024-10-26T00:00:23.123245Z"},"id":"NriAECvS-AM6","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:23.476004Z","iopub.execute_input":"2025-02-24T14:00:23.476237Z","iopub.status.idle":"2025-02-24T14:00:23.890298Z","shell.execute_reply.started":"2025-02-24T14:00:23.476219Z","shell.execute_reply":"2025-02-24T14:00:23.889523Z"}},"outputs":[{"name":"stdout","text":"Number of training images: 18811\nNumber of validation images: 2566\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Load architecture\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU, Input\nfrom tensorflow.keras.optimizers import Adam\nprint('Load model')\n\n\ndef build_model():\n    model = Sequential()\n    model.add(Input(shape=(224, 224, 3)))  # Use Input layer instead of input_shape in Flatten\n    model.add(Flatten())\n    model.add(Dense(1024))  \n    model.add(LeakyReLU(negative_slope=0.01))  # First hidden layer with LeakyReLU\n\n    model.add(Dense(512))  \n    model.add(LeakyReLU(negative_slope=0.01))  # Second hidden layer with LeakyReLU\n\n    model.add(Dense(256))  \n    model.add(LeakyReLU(negative_slope=0.01))\n\n    model.add(Dense(128))  \n    model.add(LeakyReLU(negative_slope=0.01))\n    \n    model.add(Dense(len(categories)))\n    model.add(Activation('softmax'))\n   # Learning rate is changed to 0.001\n    opt = Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8, amsgrad=True, clipnorm=1.0)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nstrategy = tf.distribute.MirroredStrategy() # Strategy for multi gpu usage\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n# buiding a model inside the strategy scope\nwith strategy.scope():\n    multi_gpu_model = build_model()\n    \nmulti_gpu_model.summary()","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:25.056806Z","start_time":"2024-10-26T00:00:24.261581Z"},"id":"BNkjbY2e-AM7","outputId":"47bde031-306f-464e-8e22-cc70a7fb7c67","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:23.891022Z","iopub.execute_input":"2025-02-24T14:00:23.891578Z","iopub.status.idle":"2025-02-24T14:00:25.648314Z","shell.execute_reply.started":"2025-02-24T14:00:23.891541Z","shell.execute_reply":"2025-02-24T14:00:25.647613Z"}},"outputs":[{"name":"stdout","text":"Load model\nNumber of devices: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150528\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │     \u001b[38;5;34m154,141,696\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │           \u001b[38;5;34m1,548\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150528</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">154,141,696</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m154,832,268\u001b[0m (590.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,832,268</span> (590.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m154,832,268\u001b[0m (590.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,832,268</span> (590.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Callbacks\nmodel_checkpoint = ModelCheckpoint('model.keras', monitor='val_accuracy', verbose=1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.1, patience=10, verbose=1)\nearly_stop = EarlyStopping('val_accuracy', patience=40, verbose=1)\nterminate = TerminateOnNaN()\ncallbacks = [model_checkpoint, reduce_lr, early_stop, terminate]","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:26.254555Z","start_time":"2024-10-26T00:00:26.243908Z"},"id":"GGAJEfpB-AM8","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:25.648991Z","iopub.execute_input":"2025-02-24T14:00:25.649236Z","iopub.status.idle":"2025-02-24T14:00:25.656107Z","shell.execute_reply.started":"2025-02-24T14:00:25.649215Z","shell.execute_reply":"2025-02-24T14:00:25.655339Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def generator_images(objs, batch_size, do_shuffle=False):\n    while True:\n        if do_shuffle:\n            np.random.shuffle(objs)\n        groups = [objs[i:i+batch_size] for i in range(0, len(objs), batch_size)]\n        for group in groups:\n            images, labels = [], []\n            for (filename, obj) in group:\n                # Load image\n                images.append(load_geoimage(filename))\n                probabilities = np.zeros(len(categories))\n                probabilities[list(categories.values()).index(obj.category)] = 1\n                labels.append(probabilities)\n            images = np.array(images).astype(np.float32)\n            labels = np.array(labels).astype(np.float32)\n            yield images, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:25.656853Z","iopub.execute_input":"2025-02-24T14:00:25.657143Z","iopub.status.idle":"2025-02-24T14:00:25.668799Z","shell.execute_reply.started":"2025-02-24T14:00:25.657119Z","shell.execute_reply":"2025-02-24T14:00:25.668010Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Generate the list of objects from annotations\nobjs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\nobjs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n# Generators\nbatch_size = 128\ntrain_generator = generator_images(objs_train, batch_size, do_shuffle=True)\nvalid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:27.058834Z","start_time":"2024-10-26T00:00:27.022627Z"},"id":"Yht-QqUH-AM8","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:25.669546Z","iopub.execute_input":"2025-02-24T14:00:25.669815Z","iopub.status.idle":"2025-02-24T14:00:25.706529Z","shell.execute_reply.started":"2025-02-24T14:00:25.669789Z","shell.execute_reply":"2025-02-24T14:00:25.705862Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\nfrom tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:25.709061Z","iopub.execute_input":"2025-02-24T14:00:25.709267Z","iopub.status.idle":"2025-02-24T14:00:25.725720Z","shell.execute_reply.started":"2025-02-24T14:00:25.709250Z","shell.execute_reply":"2025-02-24T14:00:25.725032Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 12582438427144991972\n xla_global_id: -1,\n name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 16266690560\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 9601467637503381300\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n xla_global_id: 416903419]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import math\nimport numpy as np\n\nprint('Training model')\nepochs = 60\ntrain_steps = math.ceil(len(objs_train)/batch_size)\nvalid_steps = math.ceil(len(objs_valid)/batch_size)\n\nwith tf.device(\"/device:GPU:0\"):\n    h = multi_gpu_model.fit(train_generator, steps_per_epoch=train_steps, validation_data=valid_generator, validation_steps=valid_steps, epochs=epochs, callbacks=callbacks, verbose=1)\n# Best validation model\nbest_idx = int(np.argmax(h.history['val_accuracy']))\nbest_value = np.max(h.history['val_accuracy'])\nprint('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))","metadata":{"ExecuteTime":{"start_time":"2024-10-26T00:00:27.913670Z"},"editable":true,"id":"TrfpdECs-AM9","jupyter":{"is_executing":true},"outputId":"21d89b78-d94c-442e-9bc2-517654c0b614","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:00:25.726700Z","iopub.execute_input":"2025-02-24T14:00:25.726955Z","iopub.status.idle":"2025-02-24T15:52:18.762823Z","shell.execute_reply.started":"2025-02-24T14:00:25.726936Z","shell.execute_reply":"2025-02-24T15:52:18.762024Z"}},"outputs":[{"name":"stdout","text":"Training model\nEpoch 1/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1374 - loss: 5416.0986\nEpoch 1: val_accuracy improved from -inf to 0.21317, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 6s/step - accuracy: 0.1375 - loss: 5393.6221 - val_accuracy: 0.2132 - val_loss: 5.0021 - learning_rate: 0.0010\nEpoch 2/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.2191 - loss: 7.3211\nEpoch 2: val_accuracy improved from 0.21317 to 0.30943, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 740ms/step - accuracy: 0.2194 - loss: 7.3037 - val_accuracy: 0.3094 - val_loss: 2.4231 - learning_rate: 0.0010\nEpoch 3/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.3452 - loss: 2.7549\nEpoch 3: val_accuracy improved from 0.30943 to 0.41894, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 695ms/step - accuracy: 0.3453 - loss: 2.7553 - val_accuracy: 0.4189 - val_loss: 1.7528 - learning_rate: 0.0010\nEpoch 4/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.3894 - loss: 1.9446\nEpoch 4: val_accuracy improved from 0.41894 to 0.42362, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 670ms/step - accuracy: 0.3894 - loss: 1.9445 - val_accuracy: 0.4236 - val_loss: 3.6857 - learning_rate: 0.0010\nEpoch 5/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.3863 - loss: 2.6754\nEpoch 5: val_accuracy improved from 0.42362 to 0.43063, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 607ms/step - accuracy: 0.3865 - loss: 2.6714 - val_accuracy: 0.4306 - val_loss: 1.7355 - learning_rate: 0.0010\nEpoch 6/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.4181 - loss: 1.7364\nEpoch 6: val_accuracy did not improve from 0.43063\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 525ms/step - accuracy: 0.4181 - loss: 1.7364 - val_accuracy: 0.4209 - val_loss: 1.8143 - learning_rate: 0.0010\nEpoch 7/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.4040 - loss: 1.8991\nEpoch 7: val_accuracy improved from 0.43063 to 0.45051, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 694ms/step - accuracy: 0.4041 - loss: 1.8985 - val_accuracy: 0.4505 - val_loss: 1.7144 - learning_rate: 0.0010\nEpoch 8/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.4297 - loss: 1.6788\nEpoch 8: val_accuracy did not improve from 0.45051\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 531ms/step - accuracy: 0.4297 - loss: 1.6788 - val_accuracy: 0.4474 - val_loss: 1.6667 - learning_rate: 0.0010\nEpoch 9/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.4456 - loss: 1.6332\nEpoch 9: val_accuracy improved from 0.45051 to 0.46765, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 680ms/step - accuracy: 0.4455 - loss: 1.6336 - val_accuracy: 0.4677 - val_loss: 1.6029 - learning_rate: 0.0010\nEpoch 10/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.4424 - loss: 1.6260\nEpoch 10: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 511ms/step - accuracy: 0.4424 - loss: 1.6259 - val_accuracy: 0.4458 - val_loss: 1.6461 - learning_rate: 0.0010\nEpoch 11/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.4506 - loss: 1.6163\nEpoch 11: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 613ms/step - accuracy: 0.4506 - loss: 1.6164 - val_accuracy: 0.4384 - val_loss: 1.7125 - learning_rate: 0.0010\nEpoch 12/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.4555 - loss: 1.6007\nEpoch 12: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 614ms/step - accuracy: 0.4556 - loss: 1.6007 - val_accuracy: 0.4583 - val_loss: 1.6188 - learning_rate: 0.0010\nEpoch 13/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.4650 - loss: 1.5658\nEpoch 13: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 587ms/step - accuracy: 0.4650 - loss: 1.5660 - val_accuracy: 0.3776 - val_loss: 1.7545 - learning_rate: 0.0010\nEpoch 14/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.4588 - loss: 1.5726\nEpoch 14: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 588ms/step - accuracy: 0.4589 - loss: 1.5727 - val_accuracy: 0.4641 - val_loss: 1.5860 - learning_rate: 0.0010\nEpoch 15/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.4751 - loss: 1.5189\nEpoch 15: val_accuracy did not improve from 0.46765\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 598ms/step - accuracy: 0.4751 - loss: 1.5189 - val_accuracy: 0.4606 - val_loss: 1.5961 - learning_rate: 0.0010\nEpoch 16/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.4772 - loss: 1.5249\nEpoch 16: val_accuracy improved from 0.46765 to 0.46999, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 674ms/step - accuracy: 0.4772 - loss: 1.5249 - val_accuracy: 0.4700 - val_loss: 1.5686 - learning_rate: 0.0010\nEpoch 17/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939ms/step - accuracy: 0.4740 - loss: 1.5236\nEpoch 17: val_accuracy did not improve from 0.46999\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 945ms/step - accuracy: 0.4739 - loss: 1.5239 - val_accuracy: 0.3698 - val_loss: 1.9821 - learning_rate: 0.0010\nEpoch 18/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.4696 - loss: 1.5488\nEpoch 18: val_accuracy improved from 0.46999 to 0.48870, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 727ms/step - accuracy: 0.4697 - loss: 1.5486 - val_accuracy: 0.4887 - val_loss: 1.5275 - learning_rate: 0.0010\nEpoch 19/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890ms/step - accuracy: 0.4664 - loss: 1.5360\nEpoch 19: val_accuracy did not improve from 0.48870\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 896ms/step - accuracy: 0.4664 - loss: 1.5362 - val_accuracy: 0.4548 - val_loss: 1.5982 - learning_rate: 0.0010\nEpoch 20/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.4823 - loss: 1.5290\nEpoch 20: val_accuracy improved from 0.48870 to 0.49182, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 708ms/step - accuracy: 0.4823 - loss: 1.5290 - val_accuracy: 0.4918 - val_loss: 1.5096 - learning_rate: 0.0010\nEpoch 21/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873ms/step - accuracy: 0.4877 - loss: 1.6286\nEpoch 21: val_accuracy did not improve from 0.49182\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 879ms/step - accuracy: 0.4877 - loss: 1.6281 - val_accuracy: 0.4805 - val_loss: 1.6222 - learning_rate: 0.0010\nEpoch 22/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.4817 - loss: 1.5309\nEpoch 22: val_accuracy did not improve from 0.49182\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 617ms/step - accuracy: 0.4817 - loss: 1.5309 - val_accuracy: 0.4641 - val_loss: 1.5838 - learning_rate: 0.0010\nEpoch 23/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.4862 - loss: 1.4925\nEpoch 23: val_accuracy did not improve from 0.49182\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 600ms/step - accuracy: 0.4862 - loss: 1.4926 - val_accuracy: 0.4517 - val_loss: 1.7301 - learning_rate: 0.0010\nEpoch 24/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.4775 - loss: 1.5319\nEpoch 24: val_accuracy did not improve from 0.49182\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 580ms/step - accuracy: 0.4775 - loss: 1.5316 - val_accuracy: 0.4793 - val_loss: 1.5769 - learning_rate: 0.0010\nEpoch 25/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.4880 - loss: 1.4801\nEpoch 25: val_accuracy did not improve from 0.49182\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 588ms/step - accuracy: 0.4880 - loss: 1.4803 - val_accuracy: 0.4809 - val_loss: 1.6810 - learning_rate: 0.0010\nEpoch 26/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.4932 - loss: 1.4840\nEpoch 26: val_accuracy improved from 0.49182 to 0.49805, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 691ms/step - accuracy: 0.4932 - loss: 1.4840 - val_accuracy: 0.4981 - val_loss: 1.5127 - learning_rate: 0.0010\nEpoch 27/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892ms/step - accuracy: 0.4989 - loss: 1.4563\nEpoch 27: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 898ms/step - accuracy: 0.4989 - loss: 1.4563 - val_accuracy: 0.4969 - val_loss: 1.5035 - learning_rate: 0.0010\nEpoch 28/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.4962 - loss: 1.4612\nEpoch 28: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 635ms/step - accuracy: 0.4962 - loss: 1.4612 - val_accuracy: 0.4423 - val_loss: 1.7229 - learning_rate: 0.0010\nEpoch 29/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.4918 - loss: 1.5101\nEpoch 29: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 591ms/step - accuracy: 0.4918 - loss: 1.5101 - val_accuracy: 0.4864 - val_loss: 1.5828 - learning_rate: 0.0010\nEpoch 30/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.4905 - loss: 1.5296\nEpoch 30: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 589ms/step - accuracy: 0.4905 - loss: 1.5295 - val_accuracy: 0.4856 - val_loss: 1.5738 - learning_rate: 0.0010\nEpoch 31/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.5016 - loss: 1.4553\nEpoch 31: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 587ms/step - accuracy: 0.5017 - loss: 1.4550 - val_accuracy: 0.4704 - val_loss: 1.5559 - learning_rate: 0.0010\nEpoch 32/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.5119 - loss: 1.4004\nEpoch 32: val_accuracy did not improve from 0.49805\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 625ms/step - accuracy: 0.5119 - loss: 1.4005 - val_accuracy: 0.4965 - val_loss: 1.5345 - learning_rate: 0.0010\nEpoch 33/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.5172 - loss: 1.3919\nEpoch 33: val_accuracy improved from 0.49805 to 0.51520, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 714ms/step - accuracy: 0.5172 - loss: 1.3920 - val_accuracy: 0.5152 - val_loss: 1.4586 - learning_rate: 0.0010\nEpoch 34/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865ms/step - accuracy: 0.5255 - loss: 1.3657\nEpoch 34: val_accuracy did not improve from 0.51520\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 871ms/step - accuracy: 0.5255 - loss: 1.3658 - val_accuracy: 0.4790 - val_loss: 1.5049 - learning_rate: 0.0010\nEpoch 35/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.5265 - loss: 7.1162\nEpoch 35: val_accuracy did not improve from 0.51520\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 609ms/step - accuracy: 0.5265 - loss: 7.1138 - val_accuracy: 0.4949 - val_loss: 1.4990 - learning_rate: 0.0010\nEpoch 36/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - accuracy: 0.5223 - loss: 1.3752\nEpoch 36: val_accuracy did not improve from 0.51520\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 584ms/step - accuracy: 0.5222 - loss: 1.3754 - val_accuracy: 0.5000 - val_loss: 1.5117 - learning_rate: 0.0010\nEpoch 37/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.5224 - loss: 1.3626\nEpoch 37: val_accuracy did not improve from 0.51520\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 597ms/step - accuracy: 0.5224 - loss: 1.3625 - val_accuracy: 0.5129 - val_loss: 1.5331 - learning_rate: 0.0010\nEpoch 38/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.5314 - loss: 1.3630\nEpoch 38: val_accuracy improved from 0.51520 to 0.52962, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 695ms/step - accuracy: 0.5314 - loss: 1.3629 - val_accuracy: 0.5296 - val_loss: 1.4114 - learning_rate: 0.0010\nEpoch 39/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - accuracy: 0.5399 - loss: 1.3297\nEpoch 39: val_accuracy did not improve from 0.52962\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1s/step - accuracy: 0.5399 - loss: 1.3297 - val_accuracy: 0.5230 - val_loss: 1.4451 - learning_rate: 0.0010\nEpoch 40/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - accuracy: 0.5368 - loss: 1.3280\nEpoch 40: val_accuracy did not improve from 0.52962\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 633ms/step - accuracy: 0.5368 - loss: 1.3280 - val_accuracy: 0.5117 - val_loss: 1.4770 - learning_rate: 0.0010\nEpoch 41/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.5422 - loss: 1.3362\nEpoch 41: val_accuracy did not improve from 0.52962\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 587ms/step - accuracy: 0.5421 - loss: 1.3364 - val_accuracy: 0.4747 - val_loss: 1.6350 - learning_rate: 0.0010\nEpoch 42/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.5326 - loss: 1.3704\nEpoch 42: val_accuracy improved from 0.52962 to 0.53936, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 677ms/step - accuracy: 0.5327 - loss: 1.3702 - val_accuracy: 0.5394 - val_loss: 1.4004 - learning_rate: 0.0010\nEpoch 43/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976ms/step - accuracy: 0.5550 - loss: 1.3008\nEpoch 43: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 982ms/step - accuracy: 0.5549 - loss: 1.3012 - val_accuracy: 0.5281 - val_loss: 1.4609 - learning_rate: 0.0010\nEpoch 44/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.5324 - loss: 1.3438\nEpoch 44: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 633ms/step - accuracy: 0.5323 - loss: 1.3440 - val_accuracy: 0.4926 - val_loss: 1.5256 - learning_rate: 0.0010\nEpoch 45/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5260 - loss: 1.4033\nEpoch 45: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 585ms/step - accuracy: 0.5260 - loss: 1.4033 - val_accuracy: 0.5055 - val_loss: 1.4751 - learning_rate: 0.0010\nEpoch 46/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.5348 - loss: 1.3321\nEpoch 46: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 588ms/step - accuracy: 0.5348 - loss: 1.3322 - val_accuracy: 0.5117 - val_loss: 1.4749 - learning_rate: 0.0010\nEpoch 47/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.5398 - loss: 1.4423\nEpoch 47: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 587ms/step - accuracy: 0.5398 - loss: 1.4422 - val_accuracy: 0.5144 - val_loss: 1.4726 - learning_rate: 0.0010\nEpoch 48/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.5444 - loss: 1.3351\nEpoch 48: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 590ms/step - accuracy: 0.5444 - loss: 1.3350 - val_accuracy: 0.4981 - val_loss: 1.5386 - learning_rate: 0.0010\nEpoch 49/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.5337 - loss: 1.4503\nEpoch 49: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 594ms/step - accuracy: 0.5338 - loss: 1.4497 - val_accuracy: 0.5366 - val_loss: 1.4172 - learning_rate: 0.0010\nEpoch 50/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.5431 - loss: 1.3067\nEpoch 50: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 596ms/step - accuracy: 0.5431 - loss: 1.3068 - val_accuracy: 0.5292 - val_loss: 1.4781 - learning_rate: 0.0010\nEpoch 51/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.5480 - loss: 1.3077\nEpoch 51: val_accuracy did not improve from 0.53936\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 589ms/step - accuracy: 0.5480 - loss: 1.3079 - val_accuracy: 0.4926 - val_loss: 1.7033 - learning_rate: 0.0010\nEpoch 52/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.5518 - loss: 1.2894\nEpoch 52: val_accuracy did not improve from 0.53936\n\nEpoch 52: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 585ms/step - accuracy: 0.5518 - loss: 1.2893 - val_accuracy: 0.5179 - val_loss: 1.5984 - learning_rate: 0.0010\nEpoch 53/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5805 - loss: 1.3269\nEpoch 53: val_accuracy improved from 0.53936 to 0.55495, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 681ms/step - accuracy: 0.5806 - loss: 1.3259 - val_accuracy: 0.5549 - val_loss: 1.3774 - learning_rate: 1.0000e-04\nEpoch 54/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.5975 - loss: 1.1385\nEpoch 54: val_accuracy improved from 0.55495 to 0.55924, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 864ms/step - accuracy: 0.5975 - loss: 1.1384 - val_accuracy: 0.5592 - val_loss: 1.3764 - learning_rate: 1.0000e-04\nEpoch 55/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.6028 - loss: 1.1182\nEpoch 55: val_accuracy did not improve from 0.55924\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 715ms/step - accuracy: 0.6028 - loss: 1.1182 - val_accuracy: 0.5546 - val_loss: 1.3916 - learning_rate: 1.0000e-04\nEpoch 56/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - accuracy: 0.6047 - loss: 1.1147\nEpoch 56: val_accuracy improved from 0.55924 to 0.56196, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 808ms/step - accuracy: 0.6047 - loss: 1.1147 - val_accuracy: 0.5620 - val_loss: 1.3864 - learning_rate: 1.0000e-04\nEpoch 57/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944ms/step - accuracy: 0.6037 - loss: 1.1258\nEpoch 57: val_accuracy did not improve from 0.56196\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 950ms/step - accuracy: 0.6037 - loss: 1.1257 - val_accuracy: 0.5620 - val_loss: 1.3949 - learning_rate: 1.0000e-04\nEpoch 58/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - accuracy: 0.6124 - loss: 1.0950\nEpoch 58: val_accuracy improved from 0.56196 to 0.56391, saving model to model.keras\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 722ms/step - accuracy: 0.6124 - loss: 1.0951 - val_accuracy: 0.5639 - val_loss: 1.3914 - learning_rate: 1.0000e-04\nEpoch 59/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - accuracy: 0.6046 - loss: 1.1059\nEpoch 59: val_accuracy did not improve from 0.56391\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 797ms/step - accuracy: 0.6046 - loss: 1.1059 - val_accuracy: 0.5616 - val_loss: 1.3999 - learning_rate: 1.0000e-04\nEpoch 60/60\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.6151 - loss: 1.0976\nEpoch 60: val_accuracy did not improve from 0.56391\n\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 610ms/step - accuracy: 0.6151 - loss: 1.0976 - val_accuracy: 0.5600 - val_loss: 1.3993 - learning_rate: 1.0000e-04\nBest validation model: epoch 58  - val_accuracy 0.5639126896858215\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"#### Validation\nCompute validation metrics.","metadata":{"editable":true,"id":"8IMMO_mT-AM9","slideshow":{"slide_type":""},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef draw_confusion_matrix(cm, categories):\n    # Draw confusion matrix\n    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n    ax = fig.add_subplot(111)\n    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n    # Rotate the tick labels and set their alignment\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    # Loop over data dimensions and create text annotations\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n    fig.tight_layout()\n    plt.savefig(\"/kaggle/working/confusion_matrix.png\", format=\"png\", bbox_inches=\"tight\")\n    plt.close()\n\n","metadata":{"id":"HAanJ-V0-AM1","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:52:18.763780Z","iopub.execute_input":"2025-02-24T15:52:18.764051Z","iopub.status.idle":"2025-02-24T15:52:18.771676Z","shell.execute_reply.started":"2025-02-24T15:52:18.764029Z","shell.execute_reply":"2025-02-24T15:52:18.770989Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nmodel = multi_gpu_model\nmulti_gpu_model.load_weights('model.keras')\ny_true, y_pred = [], []\nfor ann in anns_valid:\n    # Load image\n    image = load_geoimage(ann.filename)\n    for obj_pred in ann.objects:\n        # Generate prediction\n        warped_image = np.expand_dims(image, 0)\n        predictions = model.predict(warped_image, verbose=0)\n        # Save prediction\n        pred_category = list(categories.values())[np.argmax(predictions)]\n        pred_score = np.max(predictions)\n        y_true.append(obj_pred.category)\n        y_pred.append(pred_category)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:52:18.772334Z","iopub.execute_input":"2025-02-24T15:52:18.772521Z","iopub.status.idle":"2025-02-24T15:57:51.288874Z","shell.execute_reply.started":"2025-02-24T15:52:18.772504Z","shell.execute_reply":"2025-02-24T15:57:51.288123Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport pandas as pd\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\ndraw_confusion_matrix(cm, categories)\nresults = h.history\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n\n# Plot Accuracy\naxes[0].plot(results[\"accuracy\"], label=\"Training Accuracy\", color=\"blue\")\naxes[0].plot(results[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"green\")\naxes[0].set_ylabel(\"Accuracy\")\naxes[0].set_title(\"Accuracy Over Epochs\")\naxes[0].legend()\naxes[0].grid(True)\naxes[0].set_ylim(0, 1)  # Normalize y-axis for accuracy (0-1 range)\n\n# Plot Loss\naxes[1].plot(results[\"loss\"], label=\"Training Loss\", color=\"red\")\naxes[1].plot(results[\"val_loss\"], label=\"Validation Loss\", color=\"orange\")\naxes[1].set_ylabel(\"Loss\")\naxes[1].set_title(\"Loss Over Epochs\")\naxes[1].legend()\naxes[1].grid(True)\naxes[1].set_ylim(0, max(max(results[\"loss\"]), max(results[\"val_loss\"])) * 1.1)  # Normalize loss y-axis\n\nplt.xlabel(\"Epochs\")\nplt.tight_layout()\n\nplt.savefig(\"/kaggle/working/plot.png\", format=\"png\", bbox_inches=\"tight\")\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:57:51.289919Z","iopub.execute_input":"2025-02-24T15:57:51.290170Z","iopub.status.idle":"2025-02-24T15:57:53.431422Z","shell.execute_reply.started":"2025-02-24T15:57:51.290150Z","shell.execute_reply":"2025-02-24T15:57:53.430780Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-15-dedca14cfdc5>:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\n\n# Compute the accuracy\ncorrect_samples_class = np.diag(cm).astype(float)\ntotal_samples_class = np.sum(cm, axis=1).astype(float)\ntotal_predicts_class = np.sum(cm, axis=0).astype(float)\nprint('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\nacc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\nprint('Mean Recall: %.3f%%' % (acc.mean() * 100))\nacc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\nprint('Mean Precision: %.3f%%' % (acc.mean() * 100))\nfor idx in range(len(categories)):\n    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n    tp = cm[idx, idx]\n    fp = sum(cm[:, idx]) - tp\n    fn = sum(cm[idx, :]) - tp\n    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n    # Precision: proportion of predicted positive cases that were truly real positives.\n    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:57:53.432286Z","iopub.execute_input":"2025-02-24T15:57:53.432506Z","iopub.status.idle":"2025-02-24T15:57:53.443895Z","shell.execute_reply.started":"2025-02-24T15:57:53.432486Z","shell.execute_reply":"2025-02-24T15:57:53.443188Z"}},"outputs":[{"name":"stdout","text":"Mean Accuracy: 56.391%\nMean Recall: 46.034%\nMean Precision: 56.529%\n> Cargo plane: Recall: 77.632% Precision: 75.641% Specificity: 99.237% Dice: 76.623%\n> Helicopter: Recall: 12.500% Precision: 100.000% Specificity: 100.000% Dice: 22.222%\n> Small car: Recall: 83.301% Precision: 71.026% Specificity: 91.468% Dice: 76.676%\n> Bus: Recall: 46.332% Precision: 45.113% Specificity: 93.671% Dice: 45.714%\n> Truck: Recall: 30.000% Precision: 30.938% Specificity: 90.116% Dice: 30.462%\n> Motorboat: Recall: 44.531% Precision: 44.531% Specificity: 97.088% Dice: 44.531%\n> Fishing vessel: Recall: 31.765% Precision: 42.857% Specificity: 98.549% Dice: 36.486%\n> Dump truck: Recall: 31.081% Precision: 47.423% Specificity: 97.891% Dice: 37.551%\n> Excavator: Recall: 48.421% Precision: 51.111% Specificity: 98.219% Dice: 49.730%\n> Building: Recall: 77.975% Precision: 66.314% Specificity: 88.867% Dice: 71.673%\n> Storage tank: Recall: 28.977% Precision: 61.446% Specificity: 98.661% Dice: 39.382%\n> Shipping container: Recall: 39.891% Precision: 41.954% Specificity: 95.762% Dice: 40.896%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"#### Testing\nTry to improve the results provided in the competition.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\n\nanns = []\nfor (dirpath, dirnames, filenames) in os.walk('/kaggle/input/deep-learning/xview_recognition/xview_test'):\n    for filename in filenames:\n        image = GenericImage('xview_test/'+'/'+filename)\n        image.tile = np.array([0, 0, 224, 224])\n        obj = GenericObject()\n        obj.bb = (0, 0, 224, 224)\n        obj.category = dirpath[dirpath.rfind('/')+1:]\n        image.add_object(obj)\n        anns.append(image)\nprint('Number of testing images: ' + str(len(anns)))","metadata":{"id":"tJr_-xCt-AM-","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:57:53.444737Z","iopub.execute_input":"2025-02-24T15:57:53.445018Z","iopub.status.idle":"2025-02-24T15:57:57.440890Z","shell.execute_reply.started":"2025-02-24T15:57:53.444988Z","shell.execute_reply":"2025-02-24T15:57:57.440194Z"}},"outputs":[{"name":"stdout","text":"Number of testing images: 2635\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import numpy as np\n\nmodel.load_weights('model.keras')\npredictions_data = {\"images\": {}, \"annotations\": {}}\nfor idx, ann in enumerate(anns):\n    image_data = {\"image_id\": ann.filename.split('/')[-1], \"filename\": ann.filename, \"width\": int(ann.tile[2]), \"height\": int(ann.tile[3])}\n    predictions_data[\"images\"][idx] = image_data\n    # Load image\n    image = load_geoimage(ann.filename)\n    for obj_pred in ann.objects:\n        # Generate prediction\n        warped_image = np.expand_dims(image, 0)\n        predictions = model.predict(warped_image, verbose=0)\n        # Save prediction\n        pred_category = list(categories.values())[np.argmax(predictions)]\n        pred_score = np.max(predictions)\n        annotation_data = {\"image_id\": ann.filename.split('/')[-1], \"category_id\": pred_category, \"bbox\": [int(x) for x in obj_pred.bb]}\n        predictions_data[\"annotations\"][idx] = annotation_data","metadata":{"id":"TGs2zqfv-AM_","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:57:57.441616Z","iopub.execute_input":"2025-02-24T15:57:57.441831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/working/prediction.json\", \"w\") as outfile:\n    json.dump(predictions_data, outfile)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}